{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T23:35:06.686731Z",
     "start_time": "2023-08-23T23:35:06.678066Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "# PAPER_URL = \"https://arxiv.org/pdf/2110.08207.pdf\"\n",
    "PAPER_URL = \"https://arxiv.org/pdf/2201.11903.pdf\"  # Chain of thought prompting paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T23:35:07.704083Z",
     "start_time": "2023-08-23T23:35:07.687115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"URL processing started\"}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"url\": PAPER_URL\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/add/\", json=payload)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T23:29:43.069232Z",
     "start_time": "2023-08-23T23:29:41.954728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2201.11903.pdf\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mBASE_URL\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/ask/\u001B[39m\u001B[38;5;124m\"\u001B[39m, json\u001B[38;5;241m=\u001B[39mpayload)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(PAPER_URL)\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/mambaforge/lib/python3.10/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[0;32m~/mambaforge/lib/python3.10/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[0;32m~/mambaforge/lib/python3.10/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscan_once(s, idx)\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "payload = {\n",
    "    \"url\": PAPER_URL,\n",
    "    \"question\": \"What problems does this paper discuss?\"\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/ask/\", json=payload)\n",
    "print(PAPER_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'{\"status\":\"URL processing started\"}'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T23:38:44.554695Z",
     "start_time": "2023-08-23T23:38:44.549947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T23:38:50.883591Z",
     "start_time": "2023-08-23T23:38:50.867356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This collection of texts covers a wide range of topics related to language models and reasoning abilities. It explores the concept of \"chain-of-thought prompting,\" which enhances the performance of language models in complex reasoning tasks. The texts discuss the effectiveness of this approach in improving arithmetic, commonsense, and symbolic reasoning tasks. Readers will learn about the benefits of chain-of-thought prompting, such as state-of-the-art performance in math word problems and potential applications in few-shot learning. The texts also touch on the challenges and limitations of implementing this approach, the importance of prompt engineering, and the impact of model scale on reasoning abilities. Overall, the texts aim to inform readers about the effectiveness of chain-of-thought prompting and its potential for improving the performance of language models in reasoning tasks.\n",
      "\n",
      "The second passage focuses on experimental results and data analysis. It discusses an experiment comparing chain-of-thought prompting with standard prompting for different datasets. The results show that chain-of-thought prompting consistently outperforms standard prompting regardless of the number of few-shot exemplars used. The passage provides examples of correct and incorrect chains of thought produced by the language model. It also mentions the specific math word problem benchmarks used in the experiment and the datasets related to date understanding, sports understanding, arithmetic, and commonsense. Readers can learn about the comparison between chain-of-thought prompting and standard prompting, the performance of the language model on various tasks, the datasets used, specific examples of correct and incorrect answers, and the resources and measures taken for reproducibility.\n",
      "\n",
      "The third text covers various topics such as math word problems, algebraic equations, letter concatenation, and coin flipping. Readers can learn how to solve simple addition and subtraction problems, manipulate algebraic equations, combine letters to form new words, and understand coin flip probabilities. These examples provide practical knowledge and problem-solving skills in different areas.\n",
      "\n",
      "The fourth text is a compilation of prompts and answers covering different topics like basketball, hockey, dates, scheduling appointments, math word problems, letter concatenation, and coin flips. Readers can learn about sports terms, calculating dates and time intervals, solving math word problems, letter combination techniques, and understanding coin flip probabilities. The examples provide clarity on how to reason through these topics.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"url\": PAPER_URL,\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/summarise/\", json=payload)\n",
    "print(json.loads(response.text)[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2201.11903.pdf\n",
      "To improve prompting in language models, the concept of \"chain-of-thought prompting\" can be utilized. This approach enhances the performance of language models in complex reasoning tasks. It has been found to be effective in improving arithmetic, commonsense, and symbolic reasoning tasks. Chain-of-thought prompting enables state-of-the-art performance in math word problems and potential applications in few-shot learning. However, it is important to consider prompt engineering and the impact of model scale on reasoning abilities. By implementing chain-of-thought prompting, language models can expand their capabilities and successfully perform a wider range of tasks.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"url\": PAPER_URL,\n",
    "    \"question\": \"How can we improve prompting in language models?\"\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/ask/\", json=payload)\n",
    "print(PAPER_URL)\n",
    "print(json.loads(response.text)[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T23:39:05.478701Z",
     "start_time": "2023-08-23T23:38:57.386220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2201.11903.pdf\n",
      "Chain-of-thought prompting is a method used to enhance the performance of language models in complex reasoning tasks. It involves providing a prompt that consists of a series of intermediate natural language reasoning steps, called a chain of thought, which leads to the final output. This approach has been found to be effective in improving arithmetic, commonsense, and symbolic reasoning tasks. \n",
      "\n",
      "Concrete prompt examples of chain-of-thought prompting can be seen in Figure 1 of the text. For example, in a math word problem, the prompt could consist of a series of steps that guide the language model through the reasoning process to arrive at the correct answer. Another example is providing a prompt that includes the necessary steps to solve an algebraic equation or manipulate letters to form new words. \n",
      "\n",
      "Overall, chain-of-thought prompting has shown promising results in improving the performance of language models in reasoning tasks and has wide-ranging applications in fields such as math, logic, and commonsense reasoning.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"url\": PAPER_URL,\n",
    "    \"question\": \"Provide concrete prompt examples of chain-of-thought prompting\"\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/ask/\", json=payload)\n",
    "print(PAPER_URL)\n",
    "print(json.loads(response.text)[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T23:39:40.606389Z",
     "start_time": "2023-08-23T23:39:30.361584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2201.11903.pdf\n",
      "The authors seek to improve prompting in order to enhance the performance of language models in complex reasoning tasks. They explore the concept of \"chain-of-thought prompting\" and its effectiveness in improving arithmetic, commonsense, and symbolic reasoning tasks. By improving prompting techniques, the authors aim to achieve state-of-the-art performance in math word problems and potentially enhance few-shot learning capabilities. They also discuss the challenges and limitations of implementing this approach and the impact of model scale on reasoning abilities. Overall, their goal is to inform readers about the effectiveness of chain-of-thought prompting in improving the performance of language models in reasoning tasks.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"url\": PAPER_URL,\n",
    "    \"question\": \"Why do the authors seek to improve prompting?\"\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/ask/\", json=payload)\n",
    "print(PAPER_URL)\n",
    "print(json.loads(response.text)[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T23:41:51.364459Z",
     "start_time": "2023-08-23T23:41:43.971794Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2201.11903.pdf\n",
      "Based on the provided text, there is no specific information about Batman's age. Therefore, we cannot determine how old Batman is based on this text.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"url\": PAPER_URL,\n",
    "    \"question\": \"How old is batman?\"\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/ask/\", json=payload)\n",
    "print(PAPER_URL)\n",
    "print(json.loads(response.text)[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T23:41:56.799781Z",
     "start_time": "2023-08-23T23:41:53.508445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
