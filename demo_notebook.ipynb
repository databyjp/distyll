{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo notebook - personal knowledge repo\n",
    "### Powered by Weaviate :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the functions, and instantiate the database. Then, connect to the date (collection).\n",
    "\n",
    "You'll be interacting with the data through the `collection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:42:10.706253Z",
     "start_time": "2023-07-22T18:42:09.754239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/peej/.cache/weaviate-embedded: process ID 15697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2023-07-22T19:42:10+01:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2023-07-22T19:42:10+01:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2023-07-22T19:42:10+01:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2023-07-22T19:42:10+01:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"knowledge_chunk_1Poy225PNopx\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-07-22T19:42:10+01:00\",\"took\":3344792}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:6666\",\"time\":\"2023-07-22T19:42:10+01:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found class. Skipping class creation\n",
      "Creating a new class:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"knowledge_chunk_rh5Ah0ASYpHe\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-07-22T19:42:10+01:00\",\"took\":41542}\n"
     ]
    }
   ],
   "source": [
    "import wkb\n",
    "import os\n",
    "client = wkb.start_db()\n",
    "collection = wkb.Collection(client, wkb.WV_CLASS, user_agent=f'My Project ({os.getenv(\"MY_EMAIL\")})')\n",
    "collection.set_apikey(openai_key=os.getenv(\"OPENAI_APIKEY\"))  # The class is configured to use `text2vec-openai` and `generative-openai`\n",
    "collection.reinitialize_db()  # This will delete your database!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "There are a bunch of built-in functions to make it easier to add data to your knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a text file - simply specify the path to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:15:51.530048Z",
     "start_time": "2023-07-22T18:15:49.281331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the data from ./srcdata/kubernetes_concepts_overview.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.add_text_file(\"./srcdata/kubernetes_concepts_overview.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T18:16:04.056609Z",
     "start_time": "2023-07-22T18:15:56.197080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services. It provides service discovery and load balancing, storage orchestration, automated rollouts and rollbacks, automatic bin packing, self-healing, secret and configuration management. Kubernetes aims to support a diverse variety of workloads and does not limit the types of applications supported. It is not a traditional, all-inclusive PaaS system and does not provide application-level services or deployment of source code. Kubernetes eliminates the need for orchestration and provides a set of independent, composable control processes. It is highly portable and can run on various platforms. Kubernetes combines Google's experience with best practices from the community. It evolved from the need to manage containers in a production environment and provides benefits such as agility, scalability, and resource utilization.\""
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.summarize_topic(\"kubernetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the data from https://arxiv.org/pdf/1706.03762.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": "52"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
    "collection.add_from_pdf_online(pdf_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T18:19:03.552629Z",
     "start_time": "2023-07-22T18:18:59.311153Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'In a language model, attention refers to the ability of the model to focus on specific parts of the input sequence when generating the output. It is like a spotlight that allows the model to pay more attention to certain words or phrases that are important for understanding the context and generating accurate predictions.\\n\\nAttention helps the model to capture dependencies between different words in the input sequence, regardless of their distance from each other. It allows the model to consider the relevance and importance of each word when generating the output. By attending to different parts of the input sequence, the model can better understand the relationships between words and generate more accurate and coherent responses.\\n\\nIn simpler terms, attention in a language model is like a mechanism that helps the model to pay attention to important words and phrases in the input sequence, so that it can generate more accurate and meaningful output.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.ask_object(pdf_url, \"What is attention in a language model? Explain in plain language\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T18:19:10.367708Z",
     "start_time": "2023-07-22T18:19:04.589537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the data from srcdata/llama-2.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": "274"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"srcdata/llama-2.pdf\"\n",
    "collection.add_from_pdf_local(pdf_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T18:42:51.219181Z",
     "start_time": "2023-07-22T18:42:42.985592Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'The provided text is a collection of excerpts from a document titled \"Llama 2\" that covers various topics related to the development and evaluation of pretrained and fine-tuned large language models (LLMs) optimized for dialogue use cases. The document discusses the performance of the Llama 2-Chat models compared to open-source chat models, the importance of safety testing and tuning before deploying applications of Llama 2, the impact of safety data scaling on model performance, the measurement of false refusal rates, and the use of context distillation and answer templates to enhance safety capabilities. By listening to the document, the reader can learn about the advancements in LLMs for dialogue use cases, the challenges and considerations related to safety and ethical use, and the techniques used to improve model performance and mitigate risks.\\n\\nAdditionally, the document covers topics such as the distribution of safety RM scores when adding different types of prompts, the use of context distillation and its effects on response quality, proactive risk identification or \"red teaming,\" evaluation of safety violations and helpfulness ratings, improvements in truthfulness and toxicity through fine-tuning, and the phenomenon of in-context temperature rescaling. The reader can learn about the development, evaluation, and improvements of the Llama 2-Chat language model, as well as the challenges and considerations in ensuring its safety and effectiveness.\\n\\nOther topics covered include the generalization of the notion of time and organization of knowledge in a temporal manner by Llama 2 models, the integration of LLMs with tools and understanding of tool applications and API arguments, the performance of Llama 2-Chat models compared to existing models on helpfulness and safety benchmarks, the fine-tuning methodology and safety improvements implemented in Llama 2-Chat, and the importance of openness and reproducibility in LLM development. By listening to the text, the reader can learn about the capabilities and performance of Llama 2-Chat, the integration of LLMs with tools, and the importance of safety and reproducibility in LLM development.\\n\\nFurthermore, the text covers topics related to the performance of Llama 2 models compared to other models, potential data contamination, the responsible release strategy of Llama 2, safety challenges and risks associated with large language models, and several technical details of Llama 2\\'s development, evaluation, and safety considerations. Aside from that, it delves into topics such as multi-turn prompts and evaluation, haircut recommendations, safety measurements and mitigations, techniques for safety fine-tuning, performance comparisons and benchmarks, the responsible release strategy, related work, and provides insight on evaluation procedures and limitations. By listening to the text, the reader can gain knowledge about the evaluation of multi-turn prompts, recommendations for flattering haircuts, safety measurements and techniques for language models, performance comparisons with other models, and the responsible release strategy.\\n\\nLastly, the text covers various topics related to a research paper or document titled \"llama-2.pdf.\" The topics covered include annotation guidelines and safety labels, collection of human annotations, data composition and mixing, training details, reward model results, scaling trends, safety considerations, and a conclusion highlighting the competitiveness and competency of Llama 2 models. By listening to this text, the reader can learn about the technical details of Llama 2\\'s development, its evaluation results, safety considerations, and limitations. They can also gain insights into the model\\'s performance on different benchmarks, its data sources, and potential risks associated with its use. Additionally, the document provides information on contamination analysis, pronoun usage, and suggestions for finding a suitable haircut.'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.summarize_entry(pdf_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T18:44:43.588571Z",
     "start_time": "2023-07-22T18:42:58.777173Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To add a Wiki article (currently it just adds the summary) - provide the article title:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'üìö \"Llama 2\" document discusses pretrained and fine-tuned large language models (LLMs) optimized for dialogue use cases. It covers model performance, safety testing, scaling safety data, false refusal rates, and safety techniques like context distillation. Advancements, applications, and risks of LLMs are explored. #AI #LanguageModels\\n\\nüîí \"Llama 2-Chat\" model evaluation mentions safety RM scores, context distillation, and risks. Fine-tuning improves truthfulness and reduces toxicity. Reinforcement learning and human-machine synergy are effective. In-context temperature rescaling is observed. Safety and effectiveness of Llama 2-Chat are highlighted. #ModelEvaluation #Safety #FineTuning\\n\\nüåê Llama 2 and Llama 2-Chat, pretrained and fine-tuned Large Language Models (LLMs), are discussed. Generalization ability, integration with tools, math dataset performance, fine-tuning, safety improvements, and comparisons with other models are covered. Learn about capabilities, benchmarks, methodologies, and future potential. #LLMs #Research\\n\\n‚ö†Ô∏è Llama 2 language model\\'s performance compared to other models is discussed. Caution with pretrained models and responsible release strategy emphasized. Instruction tuning and RLHF used in fine-tuning. Safety challenges addressed. Learn about performance, responsible use, and safety considerations of Llama 2. #Performance #Safety #PretrainedModels\\n\\nüìù \"Llama 2\" document covers annotation guidelines, human annotations, data composition, training details, reward models, scaling trends, safety considerations, and conclusion. Achievements, safety, methodology, and references are summarized. #Annotations #Training #Safety #Achievements\\n\\nüìö Summary of topics in \"llama-2.pdf\": multi-turn prompts, haircut recommendations, safety measurements and mitigations, safety fine-tuning techniques, performance comparisons, responsible release strategy, related work, and conclusion. Learn about evaluation, safety, performance, and release. Additional info may be needed. #MultiTurnPrompts #HaircutRecommendations #Safety #Performance\\n\\nüìù \"Llama 2\" document covers details of pretraining, fine-tuning, safety evaluation, TruthfulQA evaluation, benchmark limitations, data freshness, contamination analysis, pronoun analysis, margin-based loss, haircut suggestions, and demographics. Technical details, safety, performance, limitations, and more explained. #Pretraining #SafetyEvaluation #Benchmark #HaircutSuggestions\\n\\nüìö Excerpts from a document discuss AI model impact, open releases, acknowledgment, qualitative results, pronouns, sentiment scores, starting a car without a key, language distribution, safety benchmarks, and contributions. Learn about model impact, results, behavior, and authors\\' contributions. #AIModels #OpenReleases #SentimentAnalysis\\n\\nPlease note that the provided summaries are limited to the information given and may not capture the full context or details.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.summarize_entry(pdf_path, custom_prompt=\"summarize the information into a series or two or three tweets with some emojis to make them fun and interesting\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T18:57:11.280254Z",
     "start_time": "2023-07-22T18:55:27.407702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Summary of the information:\n",
      "1. \"Llama 2\" document discusses pretrained language models optimized for dialogue use cases, safety testing, and model performance compared to open-source models. üóÇÔ∏èüöÄ\n",
      "2. Llama 2-Chat model explores safety, context distillation, and enhancing safety capabilities. üõ°Ô∏èüîí\n",
      "3. Llama 2 is a family of pretrained models with impressive generalization ability and potential as a substitute for closed-source models. üß†üí™\n",
      "4. The document covers performance comparisons, responsible use, safety considerations, and collaboration in the AI community. ‚öñÔ∏èü§ù\n",
      "5. Topics in \"llama-2.pdf\" include safety labels, human annotations, training details, reward models, and safety evaluation methods. üîñüí° \n",
      "6. The text touches on multi-turn prompts, haircuts, language model safety, techniques for fine-tuning, performance benchmarks, and related work. üíá‚Äç‚ôÇÔ∏èüìä\n",
      "7. The document highlights evaluation, benchmarks limitations, data freshness, pronoun analysis, and addressing false information. üìúüìä‚ùå\n",
      "8. Topics in AI models' impact include open releases and acknowledgments. üåçü§ù\n",
      "\n",
      "Hope this helps! Let me know if you have any other questions. üòäüëç\n"
     ]
    }
   ],
   "source": [
    "print(collection.summarize_entry(pdf_path, custom_prompt=\"summarize the information into a series or two or three short tweets, with emojis to make them fun and interesting\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T18:58:59.707137Z",
     "start_time": "2023-07-22T18:57:38.062377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'ü¶ôüî¨üöÄ Llama 2 design & training focused on safety! High importance on safety testing & tuning üë©\\u200düî¨‚úÖ They used context distillation & answer templates to enhance safety capabilities üìöüõ°Ô∏è Learn about advancements, challenges, & how they improved safety! #Llama2 #AI ü¶ôüîí\\n\\n'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.summarize_entry(pdf_path, \"Did any aspects of Llama 2 design and training involve improving safety? Summarize the answer into a short, fun, interesting tweet with emojis\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T19:32:11.995292Z",
     "start_time": "2023-07-22T19:30:29.323524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'False refusal is when a model incorrectly refuses to answer a legitimate user prompt due to irrelevant safety concerns. üö´‚ùå This can happen when the model mistakenly identifies a prompt as unsafe or potentially harmful, leading to a refusal to provide a response. It is important to train models to accurately assess safety and avoid false refusals to ensure helpful and informative interactions. #AIethics #safety'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.ask_object(pdf_path, \"what is false refusal? Explain in a short tweet with emojis\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T19:49:21.075142Z",
     "start_time": "2023-07-22T19:49:16.146472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'The safety performance of Llama 2 was measured using several methods, including safety fine-tuning, red teaming, and safety evaluation. The safety fine-tuning process involved using safety-specific data annotation and tuning to increase the safety of the models. Red teaming exercises were conducted by a set of experts to evaluate the robustness of the models and identify any vulnerabilities. Safety evaluation was performed using a set of adversarial prompts, and human raters judged the model generations for safety violations. The overall safety performance of Llama 2-Chat was compared to other open-source and closed-source models, and it generally performed better or on par with them. However, it is important to interpret these safety results carefully due to limitations such as the subjectivity of the review guidelines and individual raters. The safety performance of Llama 2 was continuously improved through iterative evaluations and model refinements. The details of these safety measurement methods can be found in the source document \"srcdata/llama-2.pdf\".'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.ask_object(pdf_path, \"how was safety performance measured with llama 2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T19:37:05.758699Z",
     "start_time": "2023-07-22T19:36:57.658775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T19:41:23.449196Z",
     "start_time": "2023-07-20T19:41:07.488993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the data from Database\n",
      "Adding the data from Vector database\n",
      "Adding the data from Containerization (computing)\n",
      "Adding the data from Formula One\n"
     ]
    }
   ],
   "source": [
    "for wiki_title in [\n",
    "    \"Database\",\n",
    "    \"Vector database\",\n",
    "    \"Containerization (computing)\",\n",
    "    \"Formula One\",\n",
    "]:\n",
    "    collection.add_wiki_article(wiki_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula One (F1) is the highest class of international racing for open-wheel single-seater formula racing cars. It is governed by the F√©d√©ration Internationale de l'Automobile (FIA) and consists of a series of races known as Grands Prix, which take place in multiple countries and continents around the world. The sport follows a set of rules and regulations, and there are two annual World Championships, one for the drivers and one for the constructors (teams).\n"
     ]
    }
   ],
   "source": [
    "print(collection.summarize_topic(\"what is formula one in a couple of sentences?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A database is an organized collection of data that is stored and accessed electronically through a database management system (DBMS). It can be used to store and retrieve large quantities of information and provides various functions for managing and organizing data.\n"
     ]
    }
   ],
   "source": [
    "print(collection.summarize_topic(\"what is a database in a couple of sentences?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T19:42:29.771645Z",
     "start_time": "2023-07-20T19:42:27.189002Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we got our prompt right - it should not give us an answer to questions like these, where we don't have any answers:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T19:42:33.926934Z",
     "start_time": "2023-07-20T19:42:32.164713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text does not contain any information about space travel.\n"
     ]
    }
   ],
   "source": [
    "print(collection.summarize_topic(\"explain space travel in a couple of sentences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to add a YouTube video: provide its URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T19:42:56.056640Z",
     "start_time": "2023-07-20T19:42:37.805150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      \r  Found Hello Weaviate - What Is a Vector? - downloading\n",
      "Successfully Downloaded to temp_audio.mp3\n",
      "Audio file under 900 seconds. No split required.\n",
      "Getting transcripts from 1 audio files...\n",
      "Processing transcript 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] unable to extract initial player response; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] unable to extract yt initial data; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] Incomplete data received in embedded initial data; re-fetching using API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the data from https://youtu.be/iFUeV3aYynI\n"
     ]
    },
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_url = \"https://youtu.be/iFUeV3aYynI\"  # Weaviate Academy - what is a vector?\n",
    "collection.add_from_youtube(youtube_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make use of your knowledge base\n",
    "\n",
    "You can use the data in your knowledge base in various ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can summarize a particular entry - for example, the YouTube video that we just ingested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T19:43:07.814840Z",
     "start_time": "2023-07-20T19:42:56.058505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This collection of videos explores the topic of vectors and their role in Weaviate. Vectors are sequences of numbers that are used to capture and represent meaning in various contexts. They are versatile and can represent complex meanings, such as colors or the essence of objects. The videos also discuss vector embeddings, which are representations of meaning obtained through deep learning models.\n",
      "\n",
      "Weaviate, being a vector database, makes use of vector embeddings to perform similarity-based searches and other operations on different types of data. By watching these videos, the reader will gain an understanding of the concept of vectors, how they capture meaning, and their practical application in Weaviate for powerful operations.\n",
      "\n",
      "In summary, this collection of videos covers the topics of vectors, vector embeddings, and their role in Weaviate. By watching these videos, the reader can learn about the concept of vectors and how they are used to capture meaning, as well as how Weaviate leverages vector embeddings for powerful operations on various types of data.\n"
     ]
    }
   ],
   "source": [
    "print(collection.summarize_entry(youtube_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can ask it to suggest key ideas that you can learn about, given a particular topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or maybe I want to share details about what I learned from a video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T15:15:49.506916Z",
     "start_time": "2023-07-20T15:15:39.390699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìΩÔ∏è Learn about vectors in Weaviate! They're series of numbers that capture meaning in different contexts. üåà They're used in photo editing, color selection, and more. Weaviate uses vector embeddings for searching and data operations. Watch the videos to understand vectors' role and applications! #Weaviate #Vectors\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Summarize the key learnings in a tweet or two\n",
    " - use emojis and make it interesting.\n",
    "\"\"\"\n",
    "print(collection.summarize_entry(youtube_url, custom_prompt=prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask questions to a particular object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T15:16:24.214889Z",
     "start_time": "2023-07-20T15:16:18.832165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A vector is a series of numbers üìä that captures meaning in various contexts. It can be used to represent colors üé® or more complex concepts. Modern AI models use vectors to represent the essence of objects, like text, code, images, and videos. These vectors are derived through deep learning models üß†. Weaviate leverages vector embeddings for similarity-based searches and powerful operations on different types of data. üöÄ #Vectors #MeaningCapture #AI\n"
     ]
    }
   ],
   "source": [
    "print(collection.ask_object(youtube_url, \"what is a vector? Explain in one tweet with emojis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
