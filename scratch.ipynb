{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-10T22:12:40.152156Z",
     "start_time": "2023-07-10T22:12:39.940344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found class. Skipping class creation\n"
     ]
    }
   ],
   "source": [
    "import wkb\n",
    "client = wkb.start_db()\n",
    "collection = wkb.Collection(client, wkb.WV_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "res = (\n",
    "    collection.client.query.aggregate(wkb.WV_CLASS)\n",
    "    .with_where({\n",
    "        \"path\": \"source_path\",\n",
    "        \"operator\": \"Equal\",\n",
    "        \"valueText\": \"https://www.youtube.com/watch?v=pGrP87gE8XU\"\n",
    "    })\n",
    "    .with_meta_count()\n",
    "    .do()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T22:12:41.044085Z",
     "start_time": "2023-07-10T22:12:41.038361Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': {'Aggregate': {'Knowledge_chunk': [{'meta': {'count': 133}}]}}}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T22:12:41.716819Z",
     "start_time": "2023-07-10T22:12:41.713049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "res = (\n",
    "    collection.client.query.get(wkb.WV_CLASS, collection._get_all_property_names())\n",
    "    .with_where({\n",
    "        \"path\": \"source_path\",\n",
    "        \"operator\": \"Equal\",\n",
    "        # \"valueText\": \"./data/kubernetes_concepts_overview.txt\"\n",
    "        \"valueText\": \"https://www.youtube.com/watch?v=pGrP87gE8XU\"\n",
    "        # \"valueText\": \"Database\"\n",
    "    })\n",
    "    .with_sort({\"path\": [\"chunk_number\"], \"order\": \"asc\" })\n",
    "    .with_offset(125)\n",
    "    .do()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T22:14:13.791758Z",
     "start_time": "2023-07-10T22:14:13.770659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': {'Get': {'Knowledge_chunk': [{'body': \"all. It's just like, I can't believe that was the thing. But like, I think when you're an engineer, when you're a software engineer, you learn to appreciate those moments because most of your job is like that. And for example, here, I really like like Greg Brockman, at least according to what I can see, according to his tweets, he seemed to be that type of person. He's like pushing through these very painful, boring details, nitty gritty details. There was some off by one error or like some redundant copying between the GPU and the CPU host or whatnot. Like, and he, after seven hours of digging deeply, he found like the problem was like obvious in retrospect, but until you find it,\",\n     'chunk_number': 125,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'},\n    {'body': \"whatnot. Like, and he, after seven hours of digging deeply, he found like the problem was like obvious in retrospect, but until you find it, right, it's like the asymmetry between verifying versus finding the solution. Very, very exciting. Yeah, there are a lot of people at Ouivier who do that better than I do. And I just respect it enormously. Every now and then I find myself doing problems like that, but yeah, that like just, you know, getting into the CPU profiling and all that kind of stuff is really a huge skill. One other thing you said that's really interesting that I relate to a lot in my life is my fiance also works at Ouivier and we work together as a\",\n     'chunk_number': 126,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'},\n    {'body': \"that's really interesting that I relate to a lot in my life is my fiance also works at Ouivier and we work together as a couple who also like talks a lot about work. And so I'm really interested to hear that, like your girlfriend is doing the product design, has all that, like my experience has been, it's like just a ton of fun. And maybe we talk about work a little more often than the normal couple would, I would say, and like- 100%. Yeah. But it also ends up being a nice conversation topic, I think, in your relationship. I don't know how my relationship would look like if we were not like connected on this project. Like most of my time,\",\n     'chunk_number': 127,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'},\n    {'body': \"your relationship. I don't know how my relationship would look like if we were not like connected on this project. Like most of my time, like the moment I wake up until 2 a.m., 3 a.m., I'm literally constantly working in one way or another with a couple of these breaks I mentioned, like, because they are important. So like, I'm not sure where I could squeeze in that additional time to keep the relationship healthy. So because of that, I'm very grateful we are actually super aligned on that front. And she and I, we are both aware of that dynamic. And yeah, I think that's exciting. Like maybe a thing that popped into my mind talking about this whole thing is, if you\",\n     'chunk_number': 128,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'},\n    {'body': \"that dynamic. And yeah, I think that's exciting. Like maybe a thing that popped into my mind talking about this whole thing is, if you know the guy who is the CEO of Ruplet, I think Amjad is his name. He's actually, I don't know if you knew this, but his wife is his co-founder. That's awesome. And that's super exciting. And they've now crossed the, like they are a unicorn company now already. And they've been in the game for like seven years. And since recently, they've been just exploding. And I think I really love to hear those stories where people are not inside of the common pattern. I really like respect that. Because the pattern is you wanna be two to three\",\n     'chunk_number': 129,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'},\n    {'body': \"stories where people are not inside of the common pattern. I really like respect that. Because the pattern is you wanna be two to three founders, like mostly guys, and then like preferably Stanford, et cetera, et cetera. Like, you know what I mean? Like those, like YC has this pattern matching and you have these companies and like there are all these expectations and statistics. And so when you hear such an outlier, like succeeds, it's very like motivating as well, right? Because that means, okay, now maybe we can do this or same with me. Like I came from like Serbia and like this guy was like just self-studying. And then all of a sudden, he's like in the best top AI like\",\n     'chunk_number': 130,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'},\n    {'body': \"from like Serbia and like this guy was like just self-studying. And then all of a sudden, he's like in the best top AI like lab in the world. Like, okay, maybe I can do this. And so like, I think those are very important for like just like hope in the world, I guess. Yeah. Awesome. Well, Alexa man, thank you so much for joining the podcast. I had so much fun talking about all the technical ideas as well as hearing about how you're managing your time or just such an exciting project. I'm so excited to see how it evolves. And thank you so much again. Thanks a lot, man. I really enjoyed the conversation.\",\n     'chunk_number': 131,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'},\n    {'body': 'how it evolves. And thank you so much again. Thanks a lot, man. I really enjoyed the conversation.',\n     'chunk_number': 132,\n     'source_path': 'https://www.youtube.com/watch?v=pGrP87gE8XU'}]}}}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T22:14:14.512262Z",
     "start_time": "2023-07-10T22:14:14.508464Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"The provided excerpts from various podcast interviews and conversations cover a range of topics related to AI, content consumption, machine learning, and productivity. The topics discussed include content consumption experiences, understanding videos, multilingual translation, research engineering, YouTube careers, AI influencers, storytelling in YouTube videos, competition in the market, graph neural networks, code base explanations, chatbots and summaries, computer vision, deep learning, language models, data sets, visual components, hybrid systems, text chunking, synthetic data, and embedding models. \\n\\nBy listening to these podcast interviews and conversations, the reader can learn about the transformation of content consumption experiences, the capabilities of tools like Ordis for video summaries and suggested questions, the background and journey of AI figures and influencers, the challenges and advancements in video content analysis, the considerations involved in fine-tuning and optimizing models, the potential of visual components and multimodal models, the applications of AI in analyzing podcast transcriptions and extracting new ideas, the importance of efficient time management, and the value of hope and perseverance in pursuing a career in AI. The language used in the text is accessible and avoids technical jargon, making it easy for a general audience to understand.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.environ[\"OPENAI_APIKEY\"]\n",
    "\n",
    "summary_texts = ['The provided text is a collection of excerpts from a podcast interview with Alexa Gordeech, a well-known AI figure. The topics covered include content consumption experiences, the importance of understanding videos, the potential of multilingual translation, the role of research engineering, the YouTube career, the evolution of AI influencers, the storytelling aspect of YouTube videos, and the value of competition in the market. By listening to the podcast, the reader can learn about the transformation of content consumption experiences, the capabilities of Ordis (a tool that provides video summaries and suggested questions), the benefits of combining paper reading with coding, the background and journey of Alexa Gordeech, and the significance of competition and learning from others in the AI field. The language used in the text is accessible and avoids technical jargon, making it easy for a general audience to understand.', \"The provided text is a transcript from a YouTube video interview. The topics covered in the conversation include graph neural networks, code base explanations, career decisions, YouTube content creation, and the use of AI in chatbots and summaries. The speaker mentions popular graph neural network models such as the graph attention network and graph convolutional networks. They also discuss their experience in explaining code bases and the motivation behind creating videos on YouTube. The conversation touches on the speaker's decision to leave DeepMind and start their own startup. The evolution of content creation on YouTube and the potential impact of new technologies are also discussed. Overall, the conversation provides insights into the speaker's experiences, interests, and perspectives on various topics related to AI and content creation.\", \"The provided text is a collection of excerpts from a conversation or interview. The topics covered include the speaker's interest in various fields, such as computer vision and deep learning, their experience working at Microsoft and DeepMind, their YouTube career, their desire to build their own company, and their thoughts on the future of AI. The reader can learn about the speaker's journey and motivations, their broad knowledge across different fields, and their passion for exploring and connecting ideas. The text is presented in a conversational style, without technical jargon, making it easily understandable for a general audience.\", 'The provided text covers several topics related to video content analysis and machine learning. The speaker discusses the complexity of processing videos due to memory and computing power requirements. They mention the historical challenges in understanding video content, including transcription difficulties. The speaker also highlights the use of heuristics in analyzing visual components in shorter videos. They anticipate the use of models like Flamingo and GPT-4 to improve video analysis. The conversation touches on the evolution of ML ops and the potential advantages of building a data engine for training models. The speaker mentions the progress made by Character AI and the potential of using ChatGBT in API integration. They also discuss the concept of symbolic vector search and neuro-symbolic systems. The conversation explores the idea of fine-tuning models and the economic feasibility of such practices. The speaker mentions the excitement surrounding mosaic ML and the infrastructure built for training large models. They discuss the potential for creating personalized experiences with video courses, including automatic chapter identification and reorganization, as well as the use of chatbots for answering questions. The speaker envisions a future where video frames are processed through a neural network to provide answers. Overall, the text provides insights into the challenges and advancements in video content analysis and machine learning.', 'The provided text is a compilation of various statements from a YouTube video discussion. The topics covered include the use of neural networks in solving complex problems, the importance of external memories and non-neural network approaches, the potential benefits of fine-tuning embedding models, the role of ML engineers in different stages of development, the value of systems like Lang Chain, Lemma Index, VV8, Pinecone, and their contribution to technological advancements, the uncertainty surrounding the future of AI frameworks, the comparison between different language models, the trade-offs of fine-tuning models, the challenges of digesting lengthy courses, the cost and scale of fine-tuning models, and the potential of incorporating fine-tuned checkpoints into a chatbot system like Ordis. By listening to the discussion, the reader can gain insights into the current state of AI technology, the challenges and opportunities in model development, and the considerations involved in fine-tuning and optimizing models for specific tasks. The text uses plain language to make the content easily understandable for a general audience.', 'The provided text covers several topics related to fine-tuning embedding models, hybrid systems, vision language models, text chunking, synthetic data, multimodal space, and the quality of embedding models. The speaker discusses the power of fine-tuning embedding models and suggests that off-the-shelf models may not perform as well as models specifically trained with relevant data. They also mention the potential of combining external memory and using fewer networks for video analysis. The speaker highlights the importance of training embedding models with diverse data and mentions the progress made by Flamingo and Character AI in this area. They discuss the democratization of machine learning through tools like Lang Chain and the advantage of web developers in app development. The speaker mentions the concept of a \"tree of thoughts\" and the idea of putting metadata into text chunks. They also discuss the value of synthetic data and the potential for new ideas in conversations and simulations. The speaker shares their goal of extracting information from visual aspects of YouTube and improving information retrieval. They express excitement about research directions in the multimodal space. The speaker acknowledges the potential limitations of embedding models and suggests that other aspects, such as text chunking logic, may have a greater impact on performance. Overall, the text provides insights into the power and limitations of embedding models, the potential of hybrid systems, and the importance of diverse data and text chunking in natural language processing tasks.', 'The provided text covers several topics related to language models, data sets, visual components, and the potential applications of AI. The first part of the text mentions a paper called \"Benchmarking Commercial Embedding API\\'s\" by Professor Jimmy Lin, which discusses various open data sets such as financial questions, nutrition facts, and multilingual datasets. The speaker also mentions the state of language models and the need for benchmarking. \\n\\nIn the second part, the speaker discusses the idea of using language models to parse documents and split them into chunks while preserving semantics. They question whether the cost of using language models for this purpose is worth it and mention the use of heuristics for text chunking.\\n\\nThe third part focuses on the importance of visual components in videos and how they may or may not add value depending on the content. The speaker mentions their previous work on vision language models and their interest in the multimodal space.\\n\\nThe fourth part discusses the speaker\\'s information diet, which includes conversations rather than reading papers. They mention the use of heuristics and embedding logic for chunking videos and the potential research ideas in this area.\\n\\nThe fifth part highlights the difficulty of finding nearest neighbors in conversations compared to images and the potential for products and research in this direction.\\n\\nThe sixth part mentions the idea of searching for similar dunks in videos and the potential for novel ideas in the visual space. They also mention a company called Gunk that works in the sales vertical and uses AI to extract information from visual components.\\n\\nThe final part discusses the potential applications of AI in analyzing podcast transcriptions and extracting new ideas from conversations. The speaker mentions the limitations of interpolation and the need for unique and new ideas.\\n\\nOverall, the text covers topics such as benchmarking embedding APIs, text chunking, visual components in videos, multimodal models, information extraction, and the potential applications of AI in various domains. The reader can learn about the challenges and possibilities in these areas and the speaker\\'s perspectives and experiences.', \"The provided text covers a range of topics related to using visual components in industries to analyze and extract information from the radio. It also discusses CRMs (customer relationship management systems) and how they process calls. The text mentions a project involving turning podcasts into a dataset and the potential for using podcast transcriptions for various purposes. It explores the idea of simulating conversations to generate more data or for entertainment purposes. The concept of generative feedback loops is introduced, where simulated conversations are saved back into a database for future searching. The text also touches on the idea of synthetic data and its potential to expand a model's knowledge. It suggests that simulating conversations could lead to the discovery of new ideas. The text mentions the use of deep learning techniques, such as tree search and language models, to improve reasoning capabilities. It acknowledges the challenges and costs associated with large language models and the need for low latency, real-time applications. Overall, the reader can learn about the potential applications and challenges of using visual components, CRMs, podcast transcriptions, simulating conversations, generative feedback loops, synthetic data, and deep learning techniques in various industries.\", 'The provided text covers several topics. The first topic is the speaker\\'s daily schedule, which includes morning and afternoon sessions of deep work. The speaker emphasizes the importance of completing deep work before a specific time to avoid losing productivity. The second topic is the distinction between builders, makers, and managers, which the speaker mentions in relation to the need for uninterrupted periods of time for deep work. The third topic is the optimization of models and techniques in the field of artificial intelligence, particularly in terms of latency and real-time applications. The speaker discusses the challenges and advancements in compressing models and making them more efficient to run. The fourth topic is the Ortis platform, which the speaker encourages people to try out and mentions the addition of new features like suggested questions for each video. The speaker also discusses the concept of a marketplace for embeddings and the potential benefits of such an approach. The fifth topic is the \"tree of thoughts\" idea, which the speaker finds exciting and discusses its potential for expanding the linear thought process into a more tree-like structure. The speaker acknowledges the cost and complexity of implementing this idea in their system. The sixth topic is the challenges of implementing features like Google sign-in, highlighting the difficulties caused by versioning and outdated documentation. The speaker emphasizes the importance of recognizing the effort required to get things done, even when they may seem conceptually easy. Overall, the text provides insights into the speaker\\'s daily routine, the challenges and advancements in AI models, the features of the Ortis platform, and the complexities of implementing certain technical features.', 'The provided text covers several topics. Firstly, it discusses the challenges of implementing ideas and getting things done, even when they may seem conceptually easy. It also mentions the idea of an embedding marketplace, where users can access and utilize embeddings from various sources without the need for vectorizing the data themselves. The text raises questions about the size and structure of paragraphs, the choice and quality of embedding models, and the possibility of creating similar marketplaces for other types of data sets. Additionally, it touches on the benefits of open-sourcing data sets and the potential for scientific research and publication using these datasets. The text also explores the gatekeeping mentality in certain data sets, such as ImageNet, and the need for certification and application processes to access them. Furthermore, it delves into the concept of periodization in weightlifting and applies it to information consumption, suggesting that increasing the complexity of information gradually can lead to better results. Lastly, it mentions the Ortis platform and its potential for personal organization and information management. Overall, the text covers topics related to idea implementation, embedding marketplaces, data set accessibility, information consumption strategies, and the Ortis platform. By listening to it, the reader can gain insights into the challenges of executing ideas, the potential benefits of embedding marketplaces, the limitations of existing data sets, and strategies for managing information effectively.', 'The video discusses the concept of organizing learning and productivity in cycles, similar to how weightlifting training is structured. The speaker explains that in weightlifting, there are macro cycles of three-month periods where weights are gradually increased, followed by a deloading phase where the weights are reduced. The speaker applies this concept to learning, suggesting that the brain should be treated as a physical entity that requires breaks and structured periods of learning. They also mention the importance of different rep ranges in weightlifting and draw an analogy to different tasks in learning, such as reading, project work, writing, and interviewing. The speaker emphasizes the need for rest, proper nutrition, and sleep in both physical training and learning. They discuss their own approach to organizing time and suggest the importance of having some structure and rigidity to enhance productivity. The video concludes with a discussion on the satisfaction and challenges of problem-solving in engineering and the importance of getting into a flow state for deep work. Overall, the video covers topics such as organizing learning in cycles, the analogy between weightlifting and learning, the importance of rest and nutrition, and the satisfaction of problem-solving. Listeners can learn about the benefits of structuring their learning and productivity, the importance of rest and self-care, and the challenges and rewards of problem-solving in engineering.', 'The provided text is a conversation between two individuals discussing various topics. The conversation covers the following topics:\\n\\n1. Time management: One person mentions that they prefer to work in three-hour increments and attend meetings. They also discuss the challenges of spending long hours on a single task.\\n\\n2. Building Ortis: The conversation touches upon the perspective of one person on breadth-first thinking and depth-first thinking in the context of building Ortis. They discuss categorizing tasks and the importance of balancing different aspects of the project, such as data pipeline, backend, frontend, UI, and user studies.\\n\\n3. Relationship dynamics: One person mentions that their girlfriend is involved in the project, and they discuss how their relationship is affected by working together. They express gratitude for being aligned on the project and finding it exciting to share work-related conversations.\\n\\n4. Appreciating problem-solving: The conversation highlights the importance of pushing through challenging and tedious tasks in engineering. They mention examples of individuals who excel at digging deeply into problems and finding solutions.\\n\\n5. Non-traditional success stories: The conversation mentions the CEO of Ruplet, whose wife is his co-founder, and their success as a unicorn company. They express admiration for stories that defy common patterns and expectations.\\n\\nBy listening to this conversation, the reader can learn about the challenges of time management, the considerations involved in building a project like Ortis, the dynamics of working with a partner, the value of perseverance in problem-solving, and the inspiration that comes from non-traditional success stories. The conversation is presented in plain language, making it easily understandable for a wide audience.', 'The text is a conversation between two individuals, discussing various topics. The conversation touches on the journey of a person from Serbia who self-studied and eventually ended up in a top AI lab, highlighting the importance of hope in the world. The conversation also includes technical ideas and the management of time in an exciting project. By listening to this conversation, the reader can learn about the experiences and challenges faced by someone pursuing a career in AI, the significance of hope, and the importance of effective time management in a project. The language used is informal and conversational, making it easily understandable for a wide audience.']\n",
    "\n",
    "\n",
    "topic_prompt = f\"\"\"\n",
    "Hello! Please summarize the following as a whole into two or three paragraphs of text.\n",
    "List the topics it covers, and what the reader might learn by listening to it\n",
    "================\n",
    "{summary_texts}\n",
    "\"\"\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": topic_prompt}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T22:32:08.098392Z",
     "start_time": "2023-07-10T22:32:04.144151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
