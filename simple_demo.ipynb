{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate database\n",
    "\n",
    "You can connect to your database like this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 6666\n"
     ]
    }
   ],
   "source": [
    "import distyll\n",
    "db = distyll.DBConnection()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:42.941991Z",
     "start_time": "2023-09-03T12:48:41.002332Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## YouTube video example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's add data from a YouTube video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "youtube_url = \"https://youtu.be/sNw40lEhaIQ\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:42.945878Z",
     "start_time": "2023-09-03T12:48:42.942585Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "52"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_from_youtube(youtube_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:42.956141Z",
     "start_time": "2023-09-03T12:48:42.946209Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can query it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "response = db.query_summary(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    object_path=youtube_url\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:49.636890Z",
     "start_time": "2023-09-03T12:48:42.956577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material is part of a series discussing contextual representations, specifically focusing on the GPT transformer-based architecture.\n",
      "- It covers topics such as autoregressive loss function, token representation, hidden representation, language modeling, transformer architecture, and masking.\n",
      "- The concept of self-attention and its role in allowing the model to look back at previous positions in a sequence when making predictions is explained.\n",
      "- The training process for a GPT-style model using \"teacher forcing\" is discussed, highlighting its significance.\n",
      "- The material briefly touches on the process of sequence generation and different strategies for sampling tokens.\n",
      "- It mentions that there are different versions of GPT and alternative models available.\n",
      "- The information provided is based on the text and may vary or become outdated over time.\n"
     ]
    }
   ],
   "source": [
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:49.645978Z",
     "start_time": "2023-09-03T12:48:49.640821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    search_query=\"open source models\",\n",
    "    object_path=youtube_url,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:55.578448Z",
     "start_time": "2023-09-03T12:48:49.644969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material describes different models in the open source side of language processing.\n",
      "- It mentions the Bloom model with 176 billion parameters.\n",
      "- It discusses the GPT-3 paper and intermediate model sizes.\n",
      "- It explains the process of language modeling and token prediction.\n",
      "- It mentions smaller models in the GPT mode.\n",
      "- It describes the structure and parameters of the GPT models.\n",
      "- It discusses the use of the model's predictions in training.\n"
     ]
    }
   ],
   "source": [
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:55.586734Z",
     "start_time": "2023-09-03T12:48:55.580781Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arxiv example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "243"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdf_url = 'https://arxiv.org/pdf/1706.03762'\n",
    "pdf_url = 'https://arxiv.org/pdf/2305.15334'\n",
    "db.add_pdf(pdf_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:48:55.603513Z",
     "start_time": "2023-09-03T12:48:55.588797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The development of a model called Gorilla\n",
      "- Comparison of Gorilla's performance to GPT-4\n",
      "- Gorilla's adaptability to document changes and ability to mitigate hallucination issues\n",
      "- Introduction of the APIBench dataset for evaluating LLMs' accuracy in using APIs\n",
      "- Integration of a retrieval system with Gorilla to improve LLMs' accuracy in using tools and updated documentation\n",
      "- Focus on enhancing the effectiveness and adaptability of LLMs in using APIs\n",
      "- Training with constraints\n",
      "- Different retrieval techniques\n",
      "- Impact of using optimal retrievers\n",
      "- Suggestion of using a better retriever for finetuning, but zero-shot finetuning as an alternative when a good retriever is not available\n",
      "- Mention of program synthesis and neural networks in program synthesis\n",
      "- Application of language models in various tasks.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_summary(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    object_path=pdf_url\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:49:03.167967Z",
     "start_time": "2023-09-03T12:48:55.597616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla is a model that generates reliable API calls to machine learning (ML) models without hallucination. It has been designed to adapt to test-time API usage changes and can satisfy constraints while picking APIs. Gorilla's performance surpasses the state-of-the-art Language Model (LLM) GPT-4 in three massive datasets that were collected. \n",
      "\n",
      "Gorilla is a retrieve-aware finetuned LLaMA-7B model specifically for API calls. It can be combined with a document retriever to adapt to test-time document changes, allowing for flexible user updates or version changes. The model has been trained to understand and reason about constraints.\n",
      "\n",
      "The integration of a retrieval system with Gorilla demonstrates the potential for LLMs to use tools more accurately, keep up with frequently updated documentation, and increase the reliability and applicability of their outputs.\n",
      "\n",
      "More information about Gorilla can be found in the source: https://arxiv.org/pdf/2305.15334\n"
     ]
    }
   ],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"how does gorilla work?\",\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:49:12.144742Z",
     "start_time": "2023-09-03T12:49:03.169035Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla reduces hallucination in LLMs (Large Language Models) by generating reliable API calls without hallucination. It surpasses the state-of-the-art LLM (GPT-4) in three massive datasets. Gorilla also demonstrates an impressive capability to adapt to test-time API usage changes and can satisfy constraints while picking APIs. Additionally, when combined with a document retriever, Gorilla shows a strong capability to adapt to test-time document changes, enabling flexible user updates or version changes. The model is retrieve-aware and finetuned specifically for API calls. Gorilla's performance is evaluated and compared with other models, and it is shown to outperform them in various configurations. The training of Gorilla enables the model to adapt to changes in API documentation, and it also demonstrates the ability to understand and reason about constraints. The successful integration of the retrieval system with Gorilla increases the reliability and applicability of its outputs.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"how does gorilla reduce hallucination in LLMs?\",\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:49:21.304825Z",
     "start_time": "2023-09-03T12:49:12.145245Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optionally, you can also specify a particular Weaviate instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "# import os\n",
    "# client = weaviate.Client(\n",
    "#     url=os.environ['JP_WCS_URL'],\n",
    "#     auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "#     additional_headers={\n",
    "#         'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "#     }\n",
    "# )\n",
    "#\n",
    "# import distyll\n",
    "# db = distyll.DBConnection(client=client)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:49:21.309196Z",
     "start_time": "2023-09-03T12:49:21.306334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:49:21.314770Z",
     "start_time": "2023-09-03T12:49:21.313060Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
