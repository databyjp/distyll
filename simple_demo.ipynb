{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate database\n",
    "\n",
    "You can connect to your database like this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 6666\n"
     ]
    }
   ],
   "source": [
    "import distyll\n",
    "db = distyll.DBConnection()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:02.843130Z",
     "start_time": "2023-09-03T12:14:57.172664Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optionally, you can also specify a particular Weaviate instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "# import os\n",
    "# client = weaviate.Client(\n",
    "#     url=os.environ['JP_WCS_URL'],\n",
    "#     auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "#     additional_headers={\n",
    "#         'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "#     }\n",
    "# )\n",
    "#\n",
    "# import distyll\n",
    "# db = distyll.DBConnection(client=client)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:02.847460Z",
     "start_time": "2023-09-03T12:15:02.843675Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## YouTube video example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's add data from a YouTube video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "youtube_url = \"https://youtu.be/sNw40lEhaIQ\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:02.850758Z",
     "start_time": "2023-09-03T12:15:02.849363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "52"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_from_youtube(youtube_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:02.861357Z",
     "start_time": "2023-09-03T12:15:02.852875Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can query it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import query"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:02.867593Z",
     "start_time": "2023-09-03T12:15:02.864062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "response = query.generate_on_summary(db=db, prompt=\"In bullet points, tell me what this material describes\", object_path=youtube_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:08.957276Z",
     "start_time": "2023-09-03T12:15:02.868243Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material is part of a series discussing contextual representations, specifically focusing on the GPT transformer-based architecture.\n",
      "- It covers topics such as autoregressive loss function, token representation, hidden representation, language modeling, transformer architecture, and masking.\n",
      "- The concept of self-attention and its role in allowing the model to look back at previous positions in a sequence when making predictions is explained.\n",
      "- The training process for a GPT-style model using \"teacher forcing\" is discussed, highlighting its significance.\n",
      "- The material briefly touches on the process of sequence generation and different strategies for sampling tokens.\n",
      "- It mentions that there are different versions of GPT and alternative models available.\n",
      "- The information provided is based on the text and may vary or become outdated over time.\n"
     ]
    }
   ],
   "source": [
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:08.962625Z",
     "start_time": "2023-09-03T12:15:08.959120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "response = query.generate_on_search(\n",
    "    db=db,\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    search_query=\"open source models\",\n",
    "    object_path=youtube_url,\n",
    "    limit=2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:12.055814Z",
     "start_time": "2023-09-03T12:15:08.965370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material describes a summary of open alternatives in the field of open source models.\n",
      "- It mentions that the information provided may be outdated.\n",
      "- It highlights the variety of models available in the open source community.\n",
      "- It mentions the Bloom model, which has 176 billion parameters and is considered extremely large.\n"
     ]
    }
   ],
   "source": [
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:12.060603Z",
     "start_time": "2023-09-03T12:15:12.056769Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arxiv example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "243"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdf_url = 'https://arxiv.org/pdf/1706.03762'\n",
    "pdf_url = 'https://arxiv.org/pdf/2305.15334'\n",
    "db.add_pdf(pdf_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:12.074614Z",
     "start_time": "2023-09-03T12:15:12.061930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This material describes a research paper titled \"Gorilla: Improving Accuracy of Large Language Models using APIs and Documentation\" published on arXiv. The paper introduces a model called Gorilla, which aims to enhance the accuracy and reduce errors in large language models (LLMs) when utilizing APIs and their documentation. It compares Gorilla's performance to GPT-4 and demonstrates its adaptability to document changes and its ability to mitigate hallucination issues. The paper also introduces the APIBench dataset for evaluating LLMs' accuracy in using APIs. It discusses topics such as training with constraints, different retrieval techniques, and the impact of using optimal retrievers. The paper suggests that using a better retriever for finetuning is preferable, but zero-shot finetuning can be an alternative when a good retriever is not available. Additionally, the text briefly mentions other topics like program synthesis, neural networks in program synthesis, and the application of language models in various tasks.\n"
     ]
    }
   ],
   "source": [
    "import query\n",
    "response = query.generate_on_summary(db=db, prompt=\"Tell me what this material describes\", object_path=pdf_url)\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:20.290082Z",
     "start_time": "2023-09-03T12:15:12.076264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla, a language model developed based on LLaMA (Language Learning for Machine Automation), enhances accuracy and reduces errors in LLMs (Large Language Models) in several ways:\n",
      "\n",
      "1. Surpassing GPT-4 Performance: Gorilla's performance surpasses GPT-4, the state-of-the-art LLM, on multiple large datasets. It outperforms GPT-4 in generating reliable API calls to ML models without hallucination.\n",
      "\n",
      "2. Adaptability to Test-Time Changes: Gorilla demonstrates a strong capability to adapt to test-time document changes. This means it can easily adjust to updates or version changes in the API documentation, enabling flexible user updates.\n",
      "\n",
      "3. Mitigating Hallucination Issues: Gorilla substantially mitigates the issue of hallucination, which refers to generating incorrect or misleading information. It generates API calls without hallucination, ensuring reliable and accurate outputs.\n",
      "\n",
      "4. Understanding and Reasoning about Constraints: Gorilla has the ability to understand and reason about constraints. This means it can take into account specific requirements or limitations while selecting APIs, ensuring that the generated API calls satisfy the given constraints.\n",
      "\n",
      "Overall, Gorilla's enhanced accuracy and reduced errors make it a powerful language model for generating reliable API calls and adapting to changes in API documentation.\n"
     ]
    }
   ],
   "source": [
    "response = query.generate_on_search(\n",
    "    db=db,\n",
    "    prompt=\"how does gorills seems to enhance accuracy and reduce errors in LLMs?\",\n",
    "    search_query=\"gorilla improvements\",\n",
    "    object_path=pdf_url,\n",
    "    limit=5\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:15:30.863639Z",
     "start_time": "2023-09-03T12:15:20.292282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla is a model that generates reliable API calls to machine learning (ML) models without hallucination. It has been designed to adapt to test-time API usage changes and can satisfy constraints while picking APIs. Gorilla's performance surpasses the state-of-the-art Language Model (LLM) GPT-4 in three massive datasets that were collected. \n",
      "\n",
      "Gorilla is a retrieve-aware finetuned LLaMA-7B model specifically for API calls. It can be combined with a document retriever to adapt to test-time document changes, allowing for flexible user updates or version changes. The model has been trained to understand and reason about constraints.\n",
      "\n",
      "The integration of a retrieval system with Gorilla demonstrates the potential for LLMs to use tools more accurately, keep up with frequently updated documentation, and increase the reliability and applicability of their outputs.\n",
      "\n",
      "More information about Gorilla can be found in the source: https://arxiv.org/pdf/2305.15334\n"
     ]
    }
   ],
   "source": [
    "response = query.generate_on_search(\n",
    "    db=db,\n",
    "    prompt=\"how does gorilla work?\",\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    "    limit=10\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:18:32.562898Z",
     "start_time": "2023-09-03T12:18:23.674051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla is a model that works by leveraging document retrieval to improve its performance. It reduces hallucination in Language Model (LLM) systems by incorporating a retrieval-aware training approach. \n",
      "\n",
      "In the zero-shot setting, Gorilla demonstrates the highest accuracy gain while maintaining good factual capability. It achieves this by effectively avoiding hallucination errors when prompted with different retrievers. The accuracy and hallucination reduction of Gorilla are compared to other models such as LLAMA, GPT-3.5, GPT-4, Claude, and HuggingFace.\n",
      "\n",
      "The performance of Gorilla is evaluated on different configurations, and it consistently outperforms other models. Even when the oracle answer is given, Gorilla remains the best-performing model. It significantly outperforms GPT-4 in terms of API functionality accuracy and reducing hallucination errors.\n",
      "\n",
      "Gorilla's retrieval-aware training enables the model to adapt to changes in the dataset and improve its performance over time. It reduces hallucination errors compared to other models, as shown in the comparison table.\n",
      "\n",
      "Overall, Gorilla's approach of incorporating document retrieval and retrieval-aware training helps improve accuracy and reduce hallucination in LLMs.\n"
     ]
    }
   ],
   "source": [
    "response = query.generate_on_search(\n",
    "    db=db,\n",
    "    prompt=\"how does gorilla work and how does it reduce hallucination in LLMs\",\n",
    "    search_query=\"gorilla algorithm and hallucination\",\n",
    "    object_path=pdf_url,\n",
    "    limit=10\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:18:15.156407Z",
     "start_time": "2023-09-03T12:18:05.256843Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
