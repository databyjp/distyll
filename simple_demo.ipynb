{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate database\n",
    "\n",
    "You can connect to your database like this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 6666\n"
     ]
    }
   ],
   "source": [
    "import distyll\n",
    "db = distyll.DBConnection()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:05.635788Z",
     "start_time": "2023-09-03T12:54:02.674284Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## YouTube video example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's add data from a YouTube video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "youtube_url = \"https://youtu.be/sNw40lEhaIQ\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:05.639319Z",
     "start_time": "2023-09-03T12:54:05.637201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "52"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_from_youtube(youtube_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:05.650915Z",
     "start_time": "2023-09-03T12:54:05.641516Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can query it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "response = db.query_summary(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    object_path=youtube_url\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:14.677755Z",
     "start_time": "2023-09-03T12:54:05.651521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material is part of a series discussing contextual representations, specifically focusing on the GPT transformer-based architecture.\n",
      "- It covers topics such as autoregressive loss function, token representation, hidden representation, language modeling, transformer architecture, and masking.\n",
      "- The concept of self-attention and its role in allowing the model to look back at previous positions in a sequence when making predictions is explained.\n",
      "- The training process for a GPT-style model using \"teacher forcing\" is discussed, highlighting its significance.\n",
      "- The material briefly touches on the process of sequence generation and different strategies for sampling tokens.\n",
      "- It mentions that there are different versions of GPT and alternative models available.\n",
      "- The information provided is based on the text and may vary or become outdated over time.\n"
     ]
    }
   ],
   "source": [
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:14.684920Z",
     "start_time": "2023-09-03T12:54:14.680672Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    search_query=\"open source models\",\n",
    "    object_path=youtube_url,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:20.817458Z",
     "start_time": "2023-09-03T12:54:14.685323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material describes contextual representations and the GPT (transformer-based architecture).\n",
      "- It explains the process of training a GPT-style model with teacher forcing.\n",
      "- It discusses how language modeling predicts scores over the entire vocabulary and makes a choice about which token to use.\n",
      "- It mentions the generation process and the decision rule applied to the model's representations.\n",
      "- It provides information about the structure and parameters of different GPT models, including GPT-1, GPT-2, and GPT-3.\n",
      "- It mentions alternative open-source models, including the Bloom model.\n"
     ]
    }
   ],
   "source": [
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:20.825282Z",
     "start_time": "2023-09-03T12:54:20.820596Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arxiv example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "243"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdf_url = 'https://arxiv.org/pdf/1706.03762'\n",
    "pdf_url = 'https://arxiv.org/pdf/2305.15334'\n",
    "db.add_pdf(pdf_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:20.840100Z",
     "start_time": "2023-09-03T12:54:20.824419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The development of a model called Gorilla\n",
      "- Comparison of Gorilla's performance to GPT-4\n",
      "- Gorilla's adaptability to document changes and ability to mitigate hallucination issues\n",
      "- Introduction of the APIBench dataset for evaluating LLMs' accuracy in using APIs\n",
      "- Integration of a retrieval system with Gorilla to improve LLMs' accuracy in using tools and updated documentation\n",
      "- Focus on enhancing the effectiveness and adaptability of LLMs in using APIs\n",
      "- Training with constraints\n",
      "- Different retrieval techniques\n",
      "- Impact of using optimal retrievers\n",
      "- Suggestion of using a better retriever for finetuning, but zero-shot finetuning as an alternative when a good retriever is not available\n",
      "- Mention of program synthesis and neural networks in program synthesis\n",
      "- Application of language models in various tasks.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_summary(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    object_path=pdf_url\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:28.503465Z",
     "start_time": "2023-09-03T12:54:20.834850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla is a finetuned LLaMA-based model that is designed to improve the performance of large language models (LLMs) such as GPT-4 when it comes to generating accurate input arguments and avoiding hallucination errors in API calls. It surpasses the performance of GPT-4 in writing API calls and can adapt to test-time document changes, allowing for flexible user updates or version changes. Gorilla integrates a retrieval system, which helps LLMs use tools more accurately and keep up with frequently updated documentation, enhancing the reliability and applicability of their outputs. Gorilla's code, model, data, and demo are available at https://gorilla.cs.berkeley.edu.\n",
      "\n",
      "The process of how Gorilla works involves collecting an API dataset and generating instruction-answer pairs. It incorporates an information-retriever into the training and inference pipelines, enabling the model to adapt to changes in API documentation. Gorilla is a retrieve-aware finetuned LLaMA-7B model specifically designed for API calls. It outperforms other models in terms of API functionality accuracy and reduces hallucination errors. Gorilla can understand and reason about constraints, making it a reliable tool for making API calls.\n",
      "\n",
      "Overall, Gorilla improves the performance of LLMs in generating accurate API calls, adapts to changes in API documentation, and enhances the reliability and applicability of their outputs.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"how does gorilla work?\",\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:41.712400Z",
     "start_time": "2023-09-03T12:54:28.505837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla reduces hallucination in LLMs by using a retrieval system and a finetuned LLaMA-based model. The retrieval system helps Gorilla adapt to test-time document changes, allowing for flexible user updates or version changes. This reduces the tendency of LLMs to generate inaccurate input arguments and hallucinate the wrong usage of an API call. Additionally, Gorilla's retrieval-aware training enables the model to understand and reason about constraints, further mitigating the issue of hallucination. Overall, Gorilla improves the accuracy of API functionality while reducing hallucination errors in LLMs.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"how does gorilla reduce hallucination in LLMs?\",\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:47.856773Z",
     "start_time": "2023-09-03T12:54:41.714195Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optionally, you can also specify a particular Weaviate instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "# import os\n",
    "# client = weaviate.Client(\n",
    "#     url=os.environ['JP_WCS_URL'],\n",
    "#     auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "#     additional_headers={\n",
    "#         'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "#     }\n",
    "# )\n",
    "#\n",
    "# import distyll\n",
    "# db = distyll.DBConnection(client=client)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:47.860666Z",
     "start_time": "2023-09-03T12:54:47.858248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T12:54:47.864853Z",
     "start_time": "2023-09-03T12:54:47.862213Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
