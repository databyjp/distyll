{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate database\n",
    "\n",
    "You can connect to your database like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T13:50:49.787095Z",
     "start_time": "2023-09-13T13:50:49.039659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/jphwang/.cache/weaviate-embedded: process ID 63681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2023-09-13T14:50:49+01:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2023-09-13T14:50:49+01:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"chunk_36d7fKskIRov\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-09-13T14:50:49+01:00\",\"took\":1233542}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"datachunk_KXbH2V85PoHM\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-09-13T14:50:49+01:00\",\"took\":1392417}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"datasource_Fwu3NBT1aiZr\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-09-13T14:50:49+01:00\",\"took\":43959}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2023-09-13T14:50:49+01:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50051\",\"time\":\"2023-09-13T14:50:49+01:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:6666\",\"time\":\"2023-09-13T14:50:49+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "import distyll\n",
    "import os\n",
    "\n",
    "# # ===== OPTION 1: Default Weaviate (Embedded) =====\n",
    "import distyll\n",
    "db = distyll.DBConnection()\n",
    "\n",
    "# # ===== OPTION 2: Custom Weaviate instance =====\n",
    "# import weaviate\n",
    "#\n",
    "# client = weaviate.Client(\n",
    "#     url=os.environ['JP_WCS_URL'],\n",
    "#     auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "# )\n",
    "# db = distyll.DBConnection(client=client)\n",
    "\n",
    "# Set OpenAI API key\n",
    "db.set_apikey(openai_key=os.environ[\"OPENAI_APIKEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T13:52:45.770914Z",
     "start_time": "2023-09-13T13:50:49.788360Z"
    }
   },
   "outputs": [],
   "source": [
    "for pdf_url in [\n",
    "    # 'https://arxiv.org/pdf/1706.03762',  # Attention is all you need\n",
    "    'https://arxiv.org/pdf/2305.15334',  # Gorilla\n",
    "    # \"https://arxiv.org/pdf/2201.11903\",  # Chain of thought prompting paper\n",
    "]:\n",
    "    db.add_arxiv(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T13:52:45.773380Z",
     "start_time": "2023-09-13T13:52:45.771653Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf_url = 'https://arxiv.org/pdf/2305.15334'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T13:52:59.958385Z",
     "start_time": "2023-09-13T13:52:45.774822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material describes a large language model called Gorilla that effectively uses tools through API calls.\n",
      "- It introduces a comprehensive dataset called APIBench and evaluates Gorilla's performance in using tools and adapting to document changes.\n",
      "- Gorilla outperforms other models in API functionality accuracy and reduces hallucination errors.\n",
      "- The material addresses the challenges of integrating tools into language models and proposes a methodology that includes self-instruct fine-tuning and retrieval.\n",
      "- It covers various topics related to language models and their interaction with APIs, including the performance of retrieval methods, benefits of fine-tuning with retrievers, issue of hallucination errors, challenge of API documentation changes, and the LLM's ability to understand constraints in API calls.\n",
      "- The material discusses the limitations and social impacts of the research, including potential bias in ML APIs.\n",
      "- In summary, the material provides valuable insights into the challenges and advancements in language models' interaction with APIs, showcasing the potential benefits and limitations of different approaches. It includes detailed information about the Gorilla model, the APIBench dataset, and the training process.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_summary(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    object_path=pdf_url\n",
    ")\n",
    "print(response.generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T13:53:17.469641Z",
     "start_time": "2023-09-13T13:52:59.960979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla is a large language model (LLM) that is connected with massive APIs (Application Programming Interfaces). It has been developed to improve the capabilities of LLMs in tasks such as natural dialogue, mathematical reasoning, and program synthesis.\n",
      "\n",
      "Gorilla's primary focus is on generating reliable API calls to machine learning models without making up false information. It can adapt to changes in API usage during testing and can satisfy constraints while selecting APIs.\n",
      "\n",
      "The model used in Gorilla has been fine-tuned to surpass the performance of other LLMs, including GPT-4, in writing API calls. When combined with a document retriever, Gorilla can also adapt to changes in documents, allowing for flexible user updates or version changes.\n",
      "\n",
      "One of the challenges in LLMs is generating accurate input arguments and avoiding incorrect usage of API calls. Gorilla addresses this challenge and improves accuracy while reducing false information.\n",
      "\n",
      "Gorilla has been compared to other state-of-the-art language models in a zero-shot setting, where it performs extremely well. It also respects constraints such as accuracy, model size, memory consumption, etc.\n",
      "\n",
      "The integration of a retrieval system with Gorilla allows for more accurate use of tools, keeping up with updated documentation, and increasing the reliability and applicability of its outputs.\n",
      "\n",
      "Overall, Gorilla enhances the abilities of LLMs in generating API calls and adapting to changes, making it a valuable tool for various tasks.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"how does gorilla work? explain in simple language\"\n",
    "\n",
    "response = db.query_chunks(\n",
    "    prompt=prompt,\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you can also specify a particular Weaviate instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T13:53:17.473785Z",
     "start_time": "2023-09-13T13:53:17.470176Z"
    }
   },
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "# import os\n",
    "# client = weaviate.Client(\n",
    "#     url=os.environ['JP_WCS_URL'],\n",
    "#     auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "#     additional_headers={\n",
    "#         'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "#     }\n",
    "# )\n",
    "#\n",
    "# import distyll\n",
    "# db = distyll.DBConnection(client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T13:53:17.477295Z",
     "start_time": "2023-09-13T13:53:17.474529Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
