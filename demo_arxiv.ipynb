{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate database\n",
    "\n",
    "You can connect to your database like this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s in %(module)s: %(message)s'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T16:54:41.006768Z",
     "start_time": "2023-09-03T16:54:41.002627Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "client = weaviate.Client(\n",
    "    url=os.environ['JP_WCS_URL'],\n",
    "    auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "    additional_headers={\n",
    "        'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T16:54:46.892589Z",
     "start_time": "2023-09-03T16:54:44.073921Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# import distyll\n",
    "# db = distyll.DBConnection()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T16:54:50.217775Z",
     "start_time": "2023-09-03T16:54:50.210525Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# client.schema.delete_all()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T16:54:52.225128Z",
     "start_time": "2023-09-03T16:54:52.220795Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-03 17:54:53,028] INFO in distyll: Found DataSource in the schema. Skipping class creation\n",
      "[2023-09-03 17:54:53,233] INFO in distyll: Found DataChunk in the schema. Skipping class creation\n"
     ]
    }
   ],
   "source": [
    "import distyll\n",
    "db = distyll.DBConnection(client=client)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T16:54:53.635529Z",
     "start_time": "2023-09-03T16:54:52.655658Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arxiv example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing https://arxiv.org/pdf/1706.03762 text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-03 18:31:24,038] INFO in media: Finished parsing 15 pages from https://arxiv.org/pdf/1706.03762\n",
      "[2023-09-03 18:32:04,354] INFO in rag: Recursively summarizing 39487\n",
      "[2023-09-03 18:32:04,354] INFO in rag: Recursively summarizing 13821\n",
      "[2023-09-03 18:32:13,567] INFO in rag: Recursively summarizing 13821\n",
      "[2023-09-03 18:32:23,075] INFO in rag: Recursively summarizing 13161\n",
      "[2023-09-03 18:32:28,994] INFO in rag: Combined summary length: 6293. Summarizing...\n",
      "[2023-09-03 18:32:28,995] INFO in rag: Recursively summarizing 6293\n"
     ]
    },
    {
     "data": {
      "text/plain": "159"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for pdf_url in [\n",
    "    'https://arxiv.org/pdf/1706.03762',  # Attention is all you need\n",
    "    'https://arxiv.org/pdf/2305.15334',  # Gorilla\n",
    "    \"https://arxiv.org/pdf/2201.11903\",  # Chain of thought prompting paper\n",
    "]:\n",
    "    db.add_arxiv(pdf_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T17:32:35.870071Z",
     "start_time": "2023-09-03T17:30:53.557185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "pdf_url = 'https://arxiv.org/pdf/2305.15334'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T17:33:10.672437Z",
     "start_time": "2023-09-03T17:33:10.668095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material describes a large language model called Gorilla and its development and performance in making API calls.\n",
      "- It discusses the challenges faced by current language models in using tools effectively and generating accurate input arguments.\n",
      "- Gorilla surpasses previous models in writing API calls and can adapt to changes in documentation.\n",
      "- The importance of fine-tuning and retrieval in improving language models' tool usage is highlighted.\n",
      "- The integration of language models with various tools and their potential as the primary interface to computing infrastructure and the web is explored.\n",
      "- The evaluation of Gorilla using a dataset called APIBench is covered.\n",
      "- The impact of retrievers on performance and the issue of hallucination errors are discussed.\n",
      "- The evaluation of API calls with constraints is examined.\n",
      "- Other related research papers on language models and program synthesis are mentioned.\n",
      "- Specific models, datasets, training details, and performance comparisons are provided.\n",
      "- API calls for object detection and evaluation tables and figures are mentioned.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_summary(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    object_path=pdf_url\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T17:33:17.461558Z",
     "start_time": "2023-09-03T17:33:11.827690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla is a large language model (LLM) that is connected with massive APIs. It is designed to improve the performance of LLMs in generating accurate input arguments and avoiding hallucination errors when making API calls. Gorilla is a finetuned LLaMA-based model that surpasses the performance of state-of-the-art LLMs like GPT-4. It can adapt to test-time document changes, allowing for flexible user updates or version changes. Gorilla also integrates a retrieval system, which helps LLMs use tools more accurately and keep up with frequently updated documentation. The code, model, data, and demo of Gorilla are available at https://gorilla.cs.berkeley.edu.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"how does gorilla work?\",\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T17:33:24.373905Z",
     "start_time": "2023-09-03T17:33:20.048718Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla reduces hallucination in Large Language Models (LLMs) by improving their ability to generate accurate input arguments and avoiding the wrong usage of an API call. It achieves this through a finetuned LLaMA-based model that surpasses the performance of state-of-the-art LLMs like GPT-4 in writing API calls. Gorilla also incorporates a document retriever, which allows it to adapt to test-time document changes and mitigate the issue of hallucination. By integrating the retrieval system with Gorilla, LLMs can use tools more accurately, keep up with frequently updated documentation, and increase the reliability and applicability of their outputs.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_chunks(\n",
    "    prompt=\"how does gorilla reduce hallucination in LLMs?\",\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T17:33:28.084955Z",
     "start_time": "2023-09-03T17:33:24.371758Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optionally, you can also specify a particular Weaviate instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "# import os\n",
    "# client = weaviate.Client(\n",
    "#     url=os.environ['JP_WCS_URL'],\n",
    "#     auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "#     additional_headers={\n",
    "#         'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "#     }\n",
    "# )\n",
    "#\n",
    "# import distyll\n",
    "# db = distyll.DBConnection(client=client)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
