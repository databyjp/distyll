{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate database\n",
    "\n",
    "You can connect to your database like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:24.124780Z",
     "start_time": "2023-09-05T12:48:23.391590Z"
    }
   },
   "outputs": [],
   "source": [
    "import distyll  # My personal demo project\n",
    "import weaviate\n",
    "import os\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=os.environ['JP_WCS_URL'],\n",
    "    auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "    additional_headers={\n",
    "        'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "    }\n",
    ")\n",
    "db = distyll.DBConnection(client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:24.128004Z",
     "start_time": "2023-09-05T12:48:24.125365Z"
    }
   },
   "outputs": [],
   "source": [
    "# import distyll  # My personal demo project\n",
    "# db = distyll.DBConnection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:24.324498Z",
     "start_time": "2023-09-05T12:48:24.129323Z"
    }
   },
   "outputs": [],
   "source": [
    "for pdf_url in [\n",
    "    'https://arxiv.org/pdf/1706.03762',  # Attention is all you need\n",
    "    'https://arxiv.org/pdf/2305.15334',  # Gorilla\n",
    "    \"https://arxiv.org/pdf/2201.11903\",  # Chain of thought prompting paper\n",
    "]:\n",
    "    db.add_arxiv(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:24.327832Z",
     "start_time": "2023-09-05T12:48:24.325368Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf_url = 'https://arxiv.org/pdf/2305.15334'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:31.333074Z",
     "start_time": "2023-09-05T12:48:24.328311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The material describes a large language model called Gorilla and its development and performance in making API calls.\n",
      "- It discusses the challenges faced by current language models in using tools effectively and generating accurate input arguments.\n",
      "- Gorilla surpasses previous models in writing API calls and can adapt to changes in documentation.\n",
      "- The importance of fine-tuning and retrieval in improving language models' tool usage is highlighted.\n",
      "- The integration of language models with various tools and their potential as the primary interface to computing infrastructure and the web is explored.\n",
      "- The evaluation of Gorilla using a dataset called APIBench is covered.\n",
      "- The impact of retrievers on performance and the issue of hallucination errors are discussed.\n",
      "- The evaluation of API calls with constraints is examined.\n",
      "- Other related research papers on language models and program synthesis are mentioned.\n",
      "- Specific models, datasets, training details, and performance comparisons are provided.\n",
      "- API calls for object detection and evaluation tables and figures are mentioned.\n"
     ]
    }
   ],
   "source": [
    "response = db.query_summary(\n",
    "    prompt=\"In bullet points, tell me what this material describes\",\n",
    "    object_path=pdf_url\n",
    ")\n",
    "print(response.generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:38.305105Z",
     "start_time": "2023-09-05T12:48:31.333691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorilla is a large language model that is designed to work with massive APIs (Application Programming Interfaces). APIs are sets of rules and protocols that allow different software applications to communicate with each other. \n",
      "\n",
      "Gorilla is specifically trained to generate accurate input arguments for API calls. This means that it can understand and use the correct information needed to make API requests. It is also trained to avoid making mistakes or \"hallucinating\" incorrect API usage.\n",
      "\n",
      "Gorilla is built on top of the LLaMA (Language Learning for Machine Automation) model and is fine-tuned to improve its performance in writing API calls. It can adapt to changes in API documentation, which means it can still work effectively even if the API documentation is updated or changed.\n",
      "\n",
      "By integrating a document retriever, Gorilla can retrieve relevant documents that provide information about the APIs it needs to use. This helps Gorilla to accurately generate API calls and keep up with frequently updated documentation.\n",
      "\n",
      "Overall, Gorilla enhances the capabilities of large language models by improving their ability to interact with APIs and use them correctly. It increases the reliability and applicability of their outputs, making them more useful in real-world applications.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"how does gorilla work? explain in simple language\"\n",
    "\n",
    "response = db.query_chunks(\n",
    "    prompt=prompt,\n",
    "    search_query=\"gorilla algorithm\",\n",
    "    object_path=pdf_url,\n",
    ")\n",
    "print(response.generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you can also specify a particular Weaviate instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:44.153861Z",
     "start_time": "2023-09-05T12:48:44.150566Z"
    }
   },
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "# import os\n",
    "# client = weaviate.Client(\n",
    "#     url=os.environ['JP_WCS_URL'],\n",
    "#     auth_client_secret=weaviate.AuthApiKey(os.environ['JP_WCS_ADMIN_KEY']),\n",
    "#     additional_headers={\n",
    "#         'X-OpenAI-Api-Key': os.environ['OPENAI_APIKEY']\n",
    "#     }\n",
    "# )\n",
    "#\n",
    "# import distyll\n",
    "# db = distyll.DBConnection(client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:48:44.156356Z",
     "start_time": "2023-09-05T12:48:44.154324Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
